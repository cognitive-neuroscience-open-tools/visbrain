{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Region Of Interest object (RoiObj) : complete tutorial\n\nThis example illustrate the main functionalities and inputs of the roi\nobject i.e :\n\n  * Use either the Brodmann, AAL, Talairach or MIST atlases and select ROI\n  * Color control of ROI\n  * Analyse source's anatomical location using an RoiObj\n  * Project source's activity onto ROI\n  * Define a custom ROI object\n\nList of supported ROI atlases :\n\n  * Brodmann areas\n  * AAL (Automated Anatomical Labeling)\n  * Talairach\n  * [MIST](https://mniopenresearch.org/articles/1-3/v1) includes multiple\n    resolutions that can be explored\n    [here](https://simexp.github.io/multiscale_dashboard/index.html?tour=1).\n    Inside visbrain, supported levels are 7, 12, 20, 36, 64, 122 and ROI.\n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>ROI atlases are stored inside NumPy files that are downloaded when needed.\n    Every ROI files is downloaded to the ~/visbrain_data/roi folder</p></div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\nfrom visbrain.objects import RoiObj, ColorbarObj, SceneObj, SourceObj, BrainObj\nfrom visbrain.io import download_file, path_to_visbrain_data, read_nifti"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download data\n In order to work, this example need to download some data i.e coordinates of\n intracranial sources and a parcellates atlas (MIST) to illustrate how to\n define your own RoiObj\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Get the path to the ~/visbrain_data/example_data folder\nvb_path = path_to_visbrain_data(folder='example_data')\n# Download (x, y, z) coordinates of intracranial sources\nmat = np.load(download_file('xyz_sample.npz', astype='example_data'))\nxyz, subjects = mat['xyz'], mat['subjects']\ndata = np.random.uniform(low=-1., high=1., size=(xyz.shape[0],))\n# Download the MIST parcellates\ndownload_file('MIST_ROI.zip', unzip=True, astype='example_data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scene creation\n First, we need to create the scene that will host objects\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Scene creation with a dark background and a custom size\nsc = SceneObj(size=(1400, 1000))\n# In this example, we also illustrate the use of the colorbar object. Hence, we\n# centralize colorbar properties inside a dictionary\nCBAR_STATE = dict(cbtxtsz=12, txtsz=10., width=.1, cbtxtsh=3.,\n                  rect=(-.3, -2., 1., 4.))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Find the index of a region of interest\n ROIs are defined with two variables : 1) a volume which contains integers\n and 2) a vector of labels which link every integer inside the volume with a\n label (for example, with the brodmann atlas, the index 4 refers to the label\n brodmann 4). Here, we illustrate how to find the index of a region of\n interest\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Method 1 :** export all ROI labels and indices in an excel file\n\nThis first method load a ROI atlas then, we use the\n:class:`visbrain.objects.RoiObj.get_labels` method to save every related ROI\ninformations in an excel file. This first method implies that you manually\ninspect in this file the index of the ROI that you're looking for.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "roi_to_find1 = RoiObj('brodmann')             # Use Brodmann areas\nref_brod = roi_to_find1.get_labels(vb_path)   # Save Brodmann\nroi_to_find1('aal')                           # Switch to AAL\nref_aal = roi_to_find1.get_labels(vb_path)    # Save AAL\nroi_to_find1('talairach')                     # Switch to Talairach\n# ref_tal = roi_to_find1.get_labels(vb_path)    # Save Talairach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Method 2 :** explicitly search where is the ROI that you're looking for\n\nHere, we use the :class:`visbrain.objects.RoiObj.where_is` method of the ROI\nobject to explicitly search string patterns\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Method 2 : use the `where_is` method\nroi_to_find1('brodmann')                      # Switch to Brodmann\nidx_ba6 = roi_to_find1.where_is('BA6')        # Find only BA6\nprint(ref_brod.loc[idx_ba6])\nroi_to_find1('aal')                           # Switch to AAL\nidx_sma = roi_to_find1.where_is('Supp Motor Area')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract the mesh of an ROI\n Once you have the index of the ROI that you want to plot, use the\n :class:`visbrain.objects.RoiObj.select_roi` method to extract the mesh (i.e\n vertices and faces) of the ROI. Here, we illustrate this question with the\n brodmann 6 ROI\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Load the brodmann 6 atlas, get the index of BA6 and extract the mesh\nroi_brod = RoiObj('brodmann')\nidx_ba6 = roi_brod.where_is('BA6')\nroi_brod.select_roi(select=idx_ba6)\n# Define a brain object and add this brain and ROI objects to the scene\nb_obj = BrainObj('B1')\nsc.add_to_subplot(b_obj, row=0, col=0, use_this_cam=True,\n                  title='Brodmann area 6 mesh')\nsc.add_to_subplot(roi_brod, row=0, col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set a unique color per ROI mesh\n If you need, you can set a unique color per plotted ROI mesh. Here, we plot\n the left and right insula and thalamus and set a unique color to each\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Load the AAL atlas\nroi_aal = RoiObj('aal')\n# Select indicies 29, 30, 77 and 78 (respectively insula left, right and\n# thalamus left and right)\nroi_aal.select_roi(select=[29, 30, 77, 78], unique_color=True, smooth=11)\n# Add the ROI to the scene\nsc.add_to_subplot(roi_aal, row=0, col=1, rotate='top', zoom=.4,\n                  title='Select and plot multiple ROI with unique colors')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Project source's data onto the surface of ROI mesh\n Once you've extract the mesh of the ROI, you can explicitly specify to the\n :class:`visbrain.object.SourceObj.project_sources` to project the activity\n onto the surface of the ROI. Here, we extract the mesh of the default mode\n network (DMN) and project source's activity on it\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define the roi object using the MIST at resolution 7\nroi_dmn = RoiObj('mist_7')\nroi_dmn.get_labels(save_to_path=vb_path)  # save the labels\ndmn_idx = roi_dmn.where_is('Default mode network')\nroi_dmn.select_roi(select=dmn_idx)\n# Define the source object and project source's data on the DMN\ns_dmn = SourceObj('SecondSources', xyz, data=data)\ns_dmn.project_sources(roi_dmn, cmap='plasma', clim=(-1., 1.), vmin=-.5,\n                      vmax=.7, under='gray', over='red')\n# Get the colorbar of the projection\ncb_dmn = ColorbarObj(s_dmn, cblabel='Source activity', **CBAR_STATE)\n# Add those objects to the scene\nsc.add_to_subplot(roi_dmn, row=0, col=2, rotate='top', zoom=.4,\n                  title=\"Project source's activity onto the DMN\")\nsc.add_to_subplot(cb_dmn, row=0, col=3, width_max=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get anatomical informations of sources\n If you defined sources (like intracranial recording sites, MEG source\n reconstruction...) you can use the SourceObj to defined those sources and\n then, the RoiObj to identify where are those sources located using the ROI\n volume. Here, we use the MIST at the `ROI` resolution to identify where are\n located those sources\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define the MIST object at the ROI level\nroi_mist = RoiObj('mist_ROI')\n# roi_mist.get_labels(save_to_path=vb_path)  # save the labels\n# Define the source object and analyse those sources using the MIST\ns_obj = SourceObj('anat', xyz, data=data)\nanalysis = s_obj.analyse_sources(roi_mist)\n# print(analysis)  # anatomical informations are included in a dataframe\n# Color those sources according to the anatomical informations\ns_obj.color_sources(analysis=analysis, color_by='name_ROI')\n# Add the source object to the scene\nsc.add_to_subplot(s_obj, row=1, col=0, rotate='top', zoom=.6,\n                  title='Get anatomical informations of sources')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>In the example above, we analyse sources using only one ROI object. But\n    you can also combine anatomical informations that come from several\n    ROI. For example, if you want to analyse your sources using brodmann\n    areas, AAL and MIST at level 7 :\n\n        brod_roi = RoiObj('brodmann')\n\n        brod_aal = RoiObj('aal')\n\n        brod_mist = RoiObj('mist_7')\n\n        s_obj.analyse_sources([brod_roi, brod_aal, brod_mist])</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Select sources that are inside an ROI\n Here, we illustrate how to only select sources that are inside the\n somatomotor network.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define the roi MIST object at level 7\nsomato_str = 'Somatomotor network'\nroi_somato = RoiObj('mist_7')\nidx_somato = roi_somato.where_is(somato_str)\nroi_somato.select_roi(idx_somato, translucent=True)\n# Define the source object and analyse anatomical informations\ns_somato = SourceObj('somato', xyz, data=data)\nanalysis = s_somato.analyse_sources(roi_somato, keep_only=somato_str)\ns_somato.color_sources(data=data, cmap='bwr')\n# Add those objects to the scene\nsc.add_to_subplot(roi_somato, row=1, col=1, use_this_cam=True, rotate='top',\n                  title='Display only sources inside the\\nsomatomotor network',\n                  zoom=.6)\nsc.add_to_subplot(s_somato, row=1, col=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define and use your own region of interest\n Visbrain comes with several ROI volumes, but you can define your own ROI\n object. To do this, you need a volume (i.e an array with three dimensions)\n and an array of labels. Here, for the sake of illustration, we explain how\n to rebuild the MIST at the ROI resolution.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Download the MIST_ROI.zip archive. See the README inside the archive\nnifti_file = path_to_visbrain_data(file='MIST_ROI.nii.gz',\n                                   folder='example_data')\ncsv_file = path_to_visbrain_data(file='MIST_ROI.csv', folder='example_data')\n# Read the .csv file :\narr = np.genfromtxt(csv_file, delimiter=';', dtype=str)\n# Get column names, labels and index :\ncolumn_names = arr[0, :]\narr = np.delete(arr, 0, 0)\nn_roi = arr.shape[0]\nroi_index = arr[:, 0].astype(int)\nroi_labels = arr[:, [1, 2]].astype(object)\n# Build the struct array :\nlabel = np.zeros(n_roi, dtype=[('label', object), ('name', object)])\nlabel['label'] = roi_labels[:, 0]\nlabel['name'] = roi_labels[:, 1]\n# Get the volume and the hdr transformation :\nvol, _, hdr = read_nifti(nifti_file, hdr_as_array=True)\n# Define the ROI object and save it :\nroi_custom = RoiObj('custom_roi', vol=vol, labels=label, index=roi_index,\n                    hdr=hdr)\n# Find thalamus entries :\nidx_thalamus = roi_custom.where_is('THALAMUS')\ncolors = {55: 'slateblue', 56: 'olive', 63: 'darkred', 64: '#ab4642'}\nroi_custom.select_roi(idx_thalamus, roi_to_color=colors)\nsc.add_to_subplot(roi_custom, row=1, col=2, zoom=.5,\n                  title='Plot dorsal and ventral thalamus with fixed colors')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>Once your RoiObj is defined, you can save it using\n    :class:`visbrain.objects.RoiObj.save`. Once the object is saved, you can\n    reload it using the name you've used (here we've used the `custom_roi`\n    name which means that you can reload it later using RoiObj('custom_roi'))</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Finally, display the scene\nsc.preview()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}