{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Source object (SourceObj) : complete tutorial\n\nThis example illustrate the main functionalities and inputs of the source\nobject i.e :\n\n    * Add sources with text\n    * Control the marker symbol and color\n    * Mask sources\n    * Analyze anatomical locations of sources using region of interest\n    * Color sources according to a data vector or to an anatomical location\n    * Display only sources in the left // right hemisphere\n    * Force source to fit to a mesh\n    * Display only sources inside // outside a mesh\n\nThe source objects can interact with several other objects :\n\n    * BrainObj : source's activity and repartition can be projected on the\n      surface of the brain\n    * RoiObj : source's activity and repartition can be projected on the\n      surface of region of interest. In addition, ROI objects can also be used\n      to get anatomical informations of sources\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\nfrom visbrain.objects import SourceObj, SceneObj, ColorbarObj, BrainObj, RoiObj\nfrom visbrain.io import download_file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-danger\"><h4>Warning</h4><p>To be clear with the vocabulary used, the SourceObj has a different\n    meaning depending on the recording type. For scalp or intracranial EEG,\n    sources reflect electrode, in MEG it could be sensors or source\n    reconstruction.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download data\n To illustrate the functionalities of the source object, here, we download an\n intracranial dataset consisting of 583 deep recording sites.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Download the file and get the (x, y, z) MNI coordinates of the 583 recording\n# sites\nmat = np.load(download_file('xyz_sample.npz', astype='example_data'))\nxyz = mat['xyz']\nn_sources = xyz.shape[0]\ntext = ['S' + str(k) for k in range(n_sources)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scene creation\n As said in other tutorials, the scene is equivalent with Matplotlib subplots.\n So here, we define a scene that is going to centralize objects in subplots\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define the default camera state used for each subplot\nCAM_STATE = dict(azimuth=0,        # azimuth angle\n                 elevation=90,     # elevation angle\n                 scale_factor=180  # distance to the camera\n                 )\nS_KW = dict(camera_state=CAM_STATE)\n# Create the scene\nsc = SceneObj(size=(1600, 1000))\nCBAR_STATE = dict(cbtxtsz=12, txtsz=10., width=.5, cbtxtsh=3.,\n                  rect=(1., -2., 1., 4.))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basic source object\n The first example consist of only plotting the source, without any\n modifications of the inputs\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create the source objects and add this object to the scene\ns_obj_basic = SourceObj('Basic', xyz)\nsc.add_to_subplot(s_obj_basic, row=0, col=0, title='Default configuration',\n                  **S_KW)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Text, symbol and color control\n Now, we attach text to each source (bold and yellow) and use a gray squares\n symbol\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# The color definition could either be uniform (e.g 'green', 'blue'...), a list\n# of colors or an array of RGB(A) colors\n# s_color = 'blue'  # uniform definition\ns_color = [\"#D72638\"] * 100 + [\"#3772FF\"] * 100 + [\"#008148\"] * 200 + \\\n    [\"#C17D11\"] * 183  # list definition\n# Define the source object and add this object to the scene\ns_obj_col = SourceObj('S2', xyz, text=text, text_size=4., text_color='yellow',\n                      text_bold=True, color=s_color, symbol='square')\nsc.add_to_subplot(s_obj_col, row=0, row_span=2, col=1,\n                  title='Text, color and symbol', **S_KW)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assigning data to sources and radius control\n This example illustrate how to assign some data to sources and how to control\n the dynamic of radius sources\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create some random data of shape (n_sources,)\nrnd_data = np.random.uniform(low=-100, high=100, size=(n_sources,))\n# Control the radius range of sources\nradius_min = 7.\nradius_max = 25.\ns_color = np.random.uniform(0., 1., (n_sources, 3))  # array definition\n# Define the source object and add this object to the scene\ns_rad = SourceObj('rad', xyz, color=s_color, data=rnd_data,\n                  radius_min=radius_min, radius_max=radius_max)\nsc.add_to_subplot(s_rad, row=0, col=2, title='Assigning data to sources ',\n                  **S_KW)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mask sources\n Sometimes, it could be usefull to mask some sources and display those sources\n with a different color (using `mask_color`).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define the mask for sources that have a x coordinate between [-20, 20] and\n# set the color of those masked sources to orange\nmask = np.logical_and(xyz[:, 0] >= -20., xyz[:, 0] <= 20.)\nmask_color = 'orange'\ns_obj_mask = SourceObj('S3', xyz, mask=mask, mask_color=mask_color,\n                       color=s_color, data=rnd_data, radius_min=radius_min,\n                       radius_max=radius_max)\nsc.add_to_subplot(s_obj_mask, row=0, col=3,\n                  title='Masked sources between [-20., 20.]\\nare orange',\n                  **S_KW)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get anatomical informations of sources\n The region of interest object (RoiObj) is basically a volume where each voxel\n is known to be part of an anatomical region. Hence, you can define the RoiObj\n and use it to get the anatomical informations of each source\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# First, create a basic source object\ns_obj_ba = SourceObj('S4', xyz)\n# Then, we define a region of interest object (RoiObj). We use brodmann areas\n# but you should take a look to the complete tutorial on ROIs because visbrain\n# povides several templates (Brodmann, AAL, Talairach and MIST)\nroi_obj = RoiObj('brodmann')\n# If you want to see labels associated with the brodmann areas, uncomment the\n# following line\n# print(roi_obj.get_labels())\n# Now, analyse sources using the RoiObj. The argument returned by the\n# `SourceObj.analyse_sources` method is a Pandas dataframe\ndf_brod = s_obj_ba.analyse_sources(roi_obj=roi_obj)\n# The dataframe contains a column `brodmann` which is the name of the\n# associated brodmann area. Hence, we use it to color sources according to the\n# name of brodmann area\ns_obj_ba.color_sources(analysis=df_brod, color_by='brodmann')\n# Finally, add the object to the scene\nsc.add_to_subplot(s_obj_ba, row=1, col=0,\n                  title='Color sources according to\\n Brodmann area', **S_KW)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Color sources, using predefined colors, according to the AAL location\n Similarly to the example above, here, we color sources according to the\n Automated Anatomical Labeling (AAL)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "\"\"\"Analyse where sources are located using the AAL ROI template and color\nonly the precentral left (green), right (orange), insula right (blue). Others\nROI are turn into white.\n\"\"\"\n# Create a basic source object\ns_obj_aal = SourceObj('S5', xyz)\n# Define the RoiObj using AAL and analyse sources locations\nroi_obj = RoiObj('aal')\n# print(roi_obj.get_labels())\ndf_aal = s_obj_aal.analyse_sources(roi_obj='aal')\n# Then, define one color per ROI and color others in gray\naal_col = {'Precentral (R)': 'green',\n           'Precentral (L)': 'orange',\n           'Insula (R)': 'blue'}\ncolor_others = 'gray'\n# Color sources and add the object to the scene\ns_obj_aal.color_sources(analysis=df_aal, color_by='aal', roi_to_color=aal_col,\n                        color_others=color_others)\nsc.add_to_subplot(s_obj_aal, row=1, col=2,\n                  title='Color only sources in\\n precentral and insula',\n                  **S_KW)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Color sources according to data\n A more simple example, but it's also possible to color your sources\n according to a data vector\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define the source object\ns_obj_data = SourceObj('S3', xyz, data=rnd_data, radius_min=radius_min,\n                       radius_max=radius_max)\n# Color sources according to a data vector\ns_obj_data.color_sources(data=rnd_data, cmap='viridis', clim=(-100, 100),)\n# Get the colorbar of the source object\ncb_data = ColorbarObj(s_obj_data, cblabel='Random data', border=False,\n                      **CBAR_STATE)\n# Add the source and colorbar objects to the scene\nsc.add_to_subplot(s_obj_data, row=1, col=3, title='Color sources using data',\n                  **S_KW)\nsc.add_to_subplot(cb_data, row=1, col=4, width_max=60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Project source's activity on the surface of the brain\n As explained in the BrainObj tutorial, source's activity can be projected on\n the surface of the brain which can be particularly convenient for represent\n source's activity across several intracranially implanted subjects\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define the source and brain objects\ns_proj = SourceObj('proj', xyz, data=rnd_data)\nb_proj = BrainObj('B3', translucent=False)\n# Project source's activity on the surface of the brain\ns_proj.project_sources(b_proj, cmap='inferno')\nsc.add_to_subplot(b_proj, row=2, col=0, title=\"Project source's activity\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Project masked source's activity on the surface of the brain\n This is the exact same example as above, except that we also project masked\n sources\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define the source and brain objects\ns_mask = SourceObj('mask', xyz, data=rnd_data, mask=mask, mask_color='gray')\nb_mask = BrainObj('B3', translucent=False)\n# Project source's activity on the surface of the brain\ns_mask.project_sources(b_mask, cmap='viridis', radius=15.)\nsc.add_to_subplot(b_mask, row=2, col=1,\n                  title=\"Project masked source's activity\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Project source's activity on the surface of the DMN\n Here, we first use the MIST ROI to get represent the default mode network and\n then, we project source's activity onto the surface of the DMN\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define the source and brain objects\ns_dmn = SourceObj('dmn', xyz, data=rnd_data, mask=mask, mask_color='gray')\nb_mask = BrainObj('B3')\n# Define the MIST roi object\nroi_dmn = RoiObj('mist_7')\n# print(roi_dmn.get_labels())\n# Get the index of the DMN and get the mesh\ndmn_idx = roi_dmn.where_is('Default mode network')\nroi_dmn.select_roi(dmn_idx)\n# Project source's activity on the surface of the DMN\ns_dmn.project_sources(roi_dmn, cmap='viridis', radius=15.)\nsc.add_to_subplot(b_mask, row=2, col=2, use_this_cam=True, row_span=2,\n                  title=\"Project source's activity\\non the DMN\")\nsc.add_to_subplot(roi_dmn, row=2, col=2, row_span=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Project source's repartition on the surface of the brain\n Similarly to the example above, we project here the repartition of sources\n which mean the number of contributing sources per vertex\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define the source and brain objects\ns_rep = SourceObj('proj', xyz, data=rnd_data)\nb_rep = BrainObj('B3', translucent=False)\n# Project source's activity on the surface of the brain\ns_rep.project_sources(b_rep, cmap='viridis', project='repartition')\n# Get the colorbar of the brain object\ncb_rep = ColorbarObj(b_rep, cblabel='Number of sources\\nper vertex',\n                     border=False, **CBAR_STATE)\nsc.add_to_subplot(b_rep, row=2, col=3, title=\"Project source's repartition\")\nsc.add_to_subplot(cb_rep, row=2, col=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Display only sources in the left hemisphere\n In this little example, we illustrate how to only display sources in the left\n hemisphere\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define the source object\ns_obj_left = SourceObj('S_left', xyz, color='#ab4642')\n# Select only sources that belong to the left hemisphere and add the object to\n# the scene\ns_obj_left.set_visible_sources('left')\nsc.add_to_subplot(s_obj_left, row=3, col=0,\n                  title='Display sources in left hemisphere', **S_KW)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Force sources to fit to the surface of the brain\n First, we force sources to fit to the white matter of the brain. Then, we use\n the talaich ROI to identify which sources belong to the left or right\n hemisphere and color them accordingly\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define the Brain and Source objects\ns_obj_fit = SourceObj('Fit', xyz, symbol='diamond')\nb_obj_fit = BrainObj('white', translucent=True)\n# Get the vertices of the brain object and force sources to fit to those\n# vertices\nb_obj_vert = b_obj_fit.vertices\ns_obj_fit.fit_to_vertices(b_obj_vert)\n# Analyse source's anatomical location using the Talairach atlas\ndf_tal = s_obj_fit.analyse_sources(roi_obj='talairach')\n# Color sources accordingly to the hemisphere (left='purple', right='yellow')\ns_obj_fit.color_sources(analysis=df_tal, color_by='hemisphere',\n                        roi_to_color={'Left': 'purple', 'Right': 'yellow'})\n# Finally, add those objects to the scene\nsc.add_to_subplot(s_obj_fit, row=3, col=1,\n                  title=\"Force sources to fit to the\\nsurface of the brain\")\nsc.add_to_subplot(b_obj_fit, row=3, col=1, use_this_cam=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Display only sources inside the brain\n In this little example, we illustrate how to only display sources inside the\n brain\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "s_obj_inside = SourceObj('In', xyz, symbol='cross', color='firebrick')\ns_obj_inside.set_visible_sources('inside', b_obj_vert)\nsc.add_to_subplot(s_obj_inside, row=3, col=3,\n                  title='Display only sources inside the brain', **S_KW)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Take a screenshot of the scene\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Screenshot of the scene\n# sc.screenshot('ex_source_obj.png', transparent=True)\n\n# If you need, you can link the rotation off all cameras but this can\n# considerably slow down visualization updates\n# sc.link(-1)\n\n# Display the scene\nsc.preview()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}